import aiohttp
import asyncio
from datetime import datetime, time
import pytz
import logging
from bs4 import BeautifulSoup
import re
from config import Config  # [ì¶”ê°€] ì„¤ì •ì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ import

logger = logging.getLogger(__name__)

class KRStockScanner:
    def __init__(self, telegram_bot, ai_analyzer):
        self.telegram = telegram_bot
        self.ai = ai_analyzer
        self.alerted_stocks = {}
        self.cooldown = 3600
        
    async def scan(self):
        """ì „ì²´ ìŠ¤ìº”"""
        all_alerts = []
        
        try:
            results = await asyncio.gather(
                self.scan_naver_news(),
                self.scan_price_surge(),
                return_exceptions=True
            )
            
            for result in results:
                if isinstance(result, Exception):
                    continue
                if result:
                    for alert in result:
                        alert['market'] = 'KR'
                    all_alerts.extend(result)
            
        except Exception as e:
            logger.error(f"í•œêµ­ ìŠ¤ìº” ì˜¤ë¥˜: {e}")
        
        return all_alerts
    
    async def scan_naver_news(self):
        """ë„¤ì´ë²„ ë‰´ìŠ¤ ìŠ¤ìº”"""
        alerts = []
        try:
            url = "https://finance.naver.com/news/news_list.naver?mode=LSS2D&section_id=101&section_id2=258"
            
            async with aiohttp.ClientSession() as session:
                headers = {'User-Agent': 'Mozilla/5.0'}
                async with session.get(url, headers=headers, timeout=10) as response:
                    if response.status != 200:
                        return alerts
                    
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    
                    # ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                    news_list = soup.select('.newsList .articleSubject')[:20]
                    
                    for news in news_list:
                        try:
                            title = news.get_text(strip=True)
                            link = "https://finance.naver.com" + news.select_one('a')['href']
                            
                            # [ìˆ˜ì •] config.pyì˜ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ì‚¬
                            if not self.is_important_kr_news(title):
                                continue
                                
                            # (ì°¸ê³ ) ë„¤ì´ë²„ ë‰´ìŠ¤ í˜ì´ì§€ëŠ” ë‰´ìŠ¤ ì œëª©ë§Œ ìˆê³  'ì–´ë–¤ ì¢…ëª©'ì¸ì§€ ë°”ë¡œ ì•Œê¸° ì–´ë ¤ìš´ êµ¬ì¡°ë¼
                            # ì—¬ê¸°ì„œëŠ” 'ì‹œì¥ ì „ì²´ì˜ í•«í•œ ë‰´ìŠ¤'ë¥¼ ê°ì§€í•˜ëŠ” ìš©ë„ë¡œ ì“°ê±°ë‚˜,
                            # ì œëª©ì— ì¢…ëª©ëª…ì´ í¬í•¨ëœ ê²½ìš°ë¥¼ ì°¾ì•„ì•¼ í•˜ëŠ”ë° ë¡œì§ì´ ë³µì¡í•˜ì—¬ ì¼ë‹¨ íŒ¨ìŠ¤í•©ë‹ˆë‹¤.
                            # ë§Œì•½ íŠ¹ì • í‚¤ì›Œë“œê°€ ë°œê²¬ë˜ë©´ 'ì‹œì¥ ì†ë³´'ë¡œ ì•Œë¦¼ì„ ë³´ë‚¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
                            
                        except:
                            continue
        except Exception as e:
            logger.error(f"ë„¤ì´ë²„ ë‰´ìŠ¤ ì˜¤ë¥˜: {e}")
        
        return alerts
    
    async def scan_price_surge(self):
        """ê¸‰ë“±ì£¼ ìŠ¤ìº” (ê±°ë˜ëŸ‰ ìƒìœ„ & ê¸‰ë“±)"""
        alerts = []
        try:
            url = "https://finance.naver.com/sise/sise_quant.naver" # ê±°ë˜ëŸ‰ ìƒìœ„
            
            async with aiohttp.ClientSession() as session:
                headers = {'User-Agent': 'Mozilla/5.0'}
                async with session.get(url, headers=headers, timeout=10) as response:
                    if response.status != 200: return alerts
                    
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    
                    rows = soup.select('table.type_2 tr')[2:22] # ìƒìœ„ê¶Œë§Œ ìŠ¤ìº”
                    
                    for row in rows:
                        try:
                            cols = row.select('td')
                            if len(cols) < 12: continue
                            
                            name_elem = cols[1].select_one('a')
                            if not name_elem: continue
                            
                            name = name_elem.get_text(strip=True)
                            href = name_elem['href']
                            code_match = re.search(r'code=(\d+)', href)
                            if not code_match: continue
                            code = code_match.group(1)
                            
                            price = int(cols[2].get_text(strip=True).replace(',', ''))
                            change_pct = float(cols[4].get_text(strip=True).replace('%', '').replace('+', ''))
                            volume = int(cols[6].get_text(strip=True).replace(',', ''))
                            
                            # í•„í„°ë§
                            if change_pct < 5.0: continue
                            if not (1000 <= price <= 500000): continue
                            
                            # ì¤‘ë³µ ë°©ì§€ (ê°„ë‹¨ ì¿¨ë‹¤ìš´)
                            if code in self.alerted_stocks:
                                last_time = self.alerted_stocks[code]
                                if (datetime.now() - last_time).seconds < self.cooldown:
                                    continue
                            
                            self.alerted_stocks[code] = datetime.now()

                            alert = {
                                'symbol': code,
                                'name': name,
                                'price': price,
                                'change_percent': change_pct,
                                'volume': volume,
                                'trigger_type': 'price_surge',
                                'trigger_reason': f'ğŸ”¥ ê±°ë˜ëŸ‰ í­ë°œ ê¸‰ë“± (+{change_pct:.1f}%)',
                                'news_url': f"https://finance.naver.com/item/main.naver?code={code}"
                            }
                            alerts.append(alert)
                            
                        except: continue
        except Exception as e:
            logger.error(f"ê¸‰ë“±ì£¼ ìŠ¤ìº” ì˜¤ë¥˜: {e}")
        
        return alerts
    
    def is_important_kr_news(self, title):
        """[ìˆ˜ì •ë¨] Config íŒŒì¼ì˜ í‚¤ì›Œë“œë¥¼ ë¶ˆëŸ¬ì™€ì„œ ê²€ì‚¬"""
        # Configì— ìˆëŠ” í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜´
        positive_keywords = Config.POSITIVE_KEYWORDS
        negative_keywords = Config.NEGATIVE_KEYWORDS
        
        # í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ True
        has_pos = any(kw in title for kw in positive_keywords)
        # í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ False (í•„í„°ë§)
        has_neg = any(kw in title for kw in negative_keywords)
        
        return has_pos and not has_neg