import aiohttp
import asyncio
from datetime import datetime
import logging
from bs4 import BeautifulSoup
import re
from config import Config

logger = logging.getLogger(__name__)

class KRStockScanner:
    def __init__(self, telegram_bot, ai_analyzer):
        self.telegram = telegram_bot
        self.ai = ai_analyzer
        self.alerted_stocks = {}
        self.cooldown = 7200 # 2ì‹œê°„ ì¿¨ë‹¤ìš´
        
    async def scan(self):
        all_alerts = []
        try:
            results = await asyncio.gather(
                self.scan_naver_news(),
                self.scan_price_surge(),
                return_exceptions=True
            )
            for result in results:
                if isinstance(result, list):
                    for alert in result: alert['market'] = 'KR'
                    all_alerts.extend(result)
        except Exception: pass
        return all_alerts
    
    async def scan_naver_news(self):
        """ë„¤ì´ë²„ ë‰´ìŠ¤ ìŠ¤ìº” (ê¸°ì¡´ ë™ì¼)"""
        alerts = []
        try:
            url = "https://finance.naver.com/news/news_list.naver?mode=LSS2D&section_id=101&section_id2=258"
            async with aiohttp.ClientSession() as session:
                headers = {'User-Agent': 'Mozilla/5.0'}
                async with session.get(url, headers=headers, timeout=10) as response:
                    if response.status != 200: return alerts
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    news_candidates = soup.select('dl.articleList dd.articleSubject a')
                    if not news_candidates: news_candidates = soup.select('ul.realtimeNewsList dl dd.articleSubject a')
                    if not news_candidates: news_candidates = soup.select('dt.articleSubject a')

                    for news in news_candidates[:15]:
                        try:
                            title = news.get('title') or news.get_text(strip=True)
                            if not title: continue
                            link = news['href']
                            if not link.startswith('http'): link = "https://finance.naver.com" + link
                            if link in self.alerted_stocks: continue
                            if self.is_important_kr_news(title):
                                self.alerted_stocks[link] = datetime.now()
                                alerts.append({'title': title, 'news_url': link, 'trigger_type': 'news', 'trigger_reason': 'ğŸ“° íŠ¹ì§•ì£¼ ë‰´ìŠ¤'})
                        except: continue
        except Exception: pass
        return alerts
    
    async def scan_price_surge(self):
        """ê¸‰ë“±ì£¼ ìŠ¤ìº” (ì‹œê°€ì´ì•¡ í•„í„° ì ìš©)"""
        alerts = []
        try:
            url = "https://finance.naver.com/sise/sise_quant.naver"
            async with aiohttp.ClientSession() as session:
                headers = {'User-Agent': 'Mozilla/5.0'}
                async with session.get(url, headers=headers, timeout=10) as response:
                    if response.status != 200: return alerts
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    rows = soup.select('table.type_2 tr')[2:100]
                    
                    for row in rows:
                        try:
                            cols = row.select('td')
                            if len(cols) < 12: continue
                            name_elem = cols[1].select_one('a')
                            if not name_elem: continue
                            
                            name = name_elem.get_text(strip=True)
                            code_match = re.search(r'code=(\d+)', name_elem['href'])
                            if not code_match: continue
                            code = code_match.group(1)
                            
                            price_txt = cols[2].get_text(strip=True).replace(',', '')
                            price = int(price_txt) if price_txt.isdigit() else 0
                            
                            change_txt = cols[4].get_text(strip=True).replace('%', '').replace('+', '').strip()
                            change_pct = float(change_txt) if change_txt.replace('.','',1).isdigit() else 0.0
                            
                            vol_txt = cols[6].get_text(strip=True).replace(',', '')
                            volume = int(vol_txt) if vol_txt.isdigit() else 0
                            
                            # ê±°ë˜ëŒ€ê¸ˆ (ì–µ ë‹¨ìœ„)
                            trade_value_100m = (price * volume) / 100000000

                            # ============================================
                            # ğŸ¯ 1. 1ì°¨ í•„í„° (ê¸°ë³¸ ì¡°ê±´)
                            # ============================================
                            if price < 1000: continue        # ë™ì „ì£¼ ì‚­ì œ
                            if price > 100000: continue      # 10ë§Œì› ì´ìƒ í™©ì œì£¼ ì‚­ì œ (ë¬´ê±°ì›€)
                            if change_pct < 4.0: continue    # 4% ë¯¸ë§Œ ì§¤ì§¤ì´ ì‚­ì œ
                            if trade_value_100m < 50: continue # 50ì–µ ë¯¸ë§Œ ê±°ë˜ëŒ€ê¸ˆ ì‚­ì œ (í™• ìƒí–¥)

                            # ì¿¨ë‹¤ìš´ ì²´í¬
                            if code in self.alerted_stocks:
                                last_alert = self.alerted_stocks[code]
                                if (datetime.now() - last_alert).total_seconds() < self.cooldown:
                                    continue

                            # ============================================
                            # ğŸ¯ 2. 2ì°¨ í•„í„° (ì‹œê°€ì´ì•¡ ì¡°íšŒ - ë¬´ê±°ìš´ ë†ˆ ì³ë‚´ê¸°)
                            # ============================================
                            market_cap_100m = await self.get_market_cap(code, session)
                            
                            # ì‹œì´ 8,000ì–µ ì´ìƒì´ë©´ "ë„ˆë¬´ ë¬´ê²ë‹¤" íŒë‹¨í•˜ì—¬ íŒ¨ìŠ¤
                            # (ë‹¨, ê±°ë˜ëŒ€ê¸ˆì´ 2,000ì–µ ì´ìƒ í„°ì§„ ì´ˆëŒ€ë°• ì£¼ë„ì£¼ëŠ” ì˜ˆì™¸ì ìœ¼ë¡œ í—ˆìš©)
                            if market_cap_100m > 8000 and trade_value_100m < 2000:
                                continue

                            # ì•Œë¦¼ ì‚¬ìœ  ì‘ì„±
                            reason = f"ğŸ’ ê°€ë²¼ìš´ ê¸‰ë“±ì£¼ (ì‹œì´ {int(market_cap_100m)}ì–µ)\nğŸ’° ê±°ë˜ëŒ€ê¸ˆ {int(trade_value_100m)}ì–µ í„°ì§ (+{change_pct:.1f}%)"
                            
                            self.alerted_stocks[code] = datetime.now()
                            alerts.append({
                                'symbol': code,
                                'name': name,
                                'price': price,
                                'change_percent': change_pct,
                                'volume': volume,
                                'trade_value_100m': trade_value_100m,
                                'trigger_type': 'price_surge',
                                'trigger_reason': reason,
                                'news_url': f"https://finance.naver.com/item/main.naver?code={code}"
                            })
                            
                        except Exception: continue
        except Exception: pass
        return alerts

    async def get_market_cap(self, code, session):
        """ì¢…ëª© ìƒì„¸ í˜ì´ì§€ì—ì„œ ì‹œê°€ì´ì•¡(ì–µ ë‹¨ìœ„) íŒŒì‹±"""
        try:
            url = f"https://finance.naver.com/item/main.naver?code={code}"
            async with session.get(url, timeout=5) as response:
                if response.status != 200: return 999999 # ì—ëŸ¬ë‚˜ë©´ ë¬´ê±°ìš´ ê±¸ë¡œ ê°„ì£¼í•´ì„œ ìŠ¤í‚µ
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                # ì‹œê°€ì´ì•¡ ì°¾ê¸° (ë„¤ì´ë²„ ê¸ˆìœµ ìƒì„¸í˜ì´ì§€ êµ¬ì¡°)
                mc_elem = soup.select_one('#_market_sum')
                if mc_elem:
                    mc_text = mc_elem.get_text(strip=True)
                    # "1ì¡° 2,345" -> 12345 (ì–µ ë‹¨ìœ„ ë³€í™˜)
                    mc_text = mc_text.replace(',', '').replace('ì¡°', '')
                    # 1ì¡°ê°€ ë„˜ìœ¼ë©´ 'ì¡°'ë¥¼ ì—†ì• ê³  ë‹¨ìœ„ë¥¼ ë§ì¶°ì•¼ í•¨.
                    # í•˜ì§€ë§Œ ë„¤ì´ë²„ëŠ” '1ì¡° 2345' í˜•íƒœë¡œ ì¤Œ. ë‹¨ìˆœ replaceí•˜ë©´ '1 2345'ê°€ ë¨.
                    # ê°„ë‹¨í•˜ê²Œ í…ìŠ¤íŠ¸ ê¸¸ì´ì™€ íŒ¨í„´ìœ¼ë¡œ ì¶”ì •
                    
                    # ì •í™•í•œ íŒŒì‹± ë¡œì§
                    val = 0
                    if 'ì¡°' in mc_elem.get_text():
                        parts = mc_elem.get_text().split('ì¡°')
                        trillion = int(re.sub(r'\D', '', parts[0])) * 10000
                        billion = 0
                        if len(parts) > 1 and parts[1].strip():
                            billion = int(re.sub(r'\D', '', parts[1]))
                        val = trillion + billion
                    else:
                        val = int(re.sub(r'\D', '', mc_elem.get_text()))
                    return val
        except: pass
        return 999999 # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì•ˆì „í•˜ê²Œ í° ê°’ ë°˜í™˜ (ì•Œë¦¼ ì œì™¸)

    def is_important_kr_news(self, title):
        has_pos = any(kw in title for kw in Config.POSITIVE_KEYWORDS)
        has_neg = any(kw in title for kw in Config.NEGATIVE_KEYWORDS)
        return has_pos and not has_neg